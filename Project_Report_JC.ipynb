{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97427b06-c579-4210-9d86-efdf42c288cf",
   "metadata": {},
   "source": [
    "Kiwi Budget : A Database of New Zealand Economic Activities (1996 ~ 2022)\n",
    "Authors : Ali, Jerry, Jeffrey\n",
    "\n",
    "Abstract\n",
    "\n",
    "This database contains information from various major social economical activities of New Zealand as well as its key monetary policy indicators. All data are time series based, they have been collected from websites like “interest.co.nz”, “interest.co.nz”, “interest.co.nz” and so on. The reuse potential includes finance department of New Zelanad companies for training machine learning algorithms that does the forecasting as well as visulisation.  This database is available through xxx??\n",
    "\n",
    "KeyWords : Monetary policy, Economic activities, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac62176-9382-490b-82ce-6930a41521db",
   "metadata": {},
   "source": [
    "(2)Methods\n",
    "Step2 \n",
    "1: Sourcing, Tidying and Enhancing New Zealand Economy Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a65d3a-b4bb-4629-96c1-fe62a1365ea4",
   "metadata": {},
   "source": [
    "We have installed following packages (\"RSelenium\", \"Writexl\" and \"here\" packages) utilized\n",
    "following libraries \n",
    "\n",
    "1) magrittr\n",
    "The magrittr (to be pronounced with a sophisticated french accent) package has two aims: decrease development time and improve readability and maintainability of code. Or even shortr: make your code smokin’ (puff puff)!\n",
    "2) polite\n",
    "Be responsible when scraping data from websites by following polite principles: introduce yourself, ask for permission, take slowly and never ask twice. \n",
    "3) rvest\n",
    "Wrappers around the 'xml2' and 'httr' packages to make it easy to download, then manipulate, HTML and XML\n",
    "4) here\n",
    "The goal of the here package is to enable easy file referencing in project-oriented workflows. In contrast to using setwd(), which is fragile and dependent on the way you organize your files, here uses the top-level directory of a project to easily build paths to files.\n",
    "5) RSelenium\n",
    "Provides a set of R bindings for the 'Selenium 2.0 WebDriver' (see <https://www.selenium.dev/documentation/> for more information) using the 'JsonWireProtocol' (see <https://github.com/SeleniumHQ/selenium/wiki/JsonWireProtocol> for more information). 'Selenium 2.0 WebDriver' allows driving a web browser natively as a user would either locally or on a remote machine using the Selenium server it marks a leap forward in terms of web browser automation. Selenium automates web browsers (commonly referred to as browsers). Using RSelenium you can automate browsers locally or remotely. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1afd7c13-d689-4d40-8054-5a3a2d8e9f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing packages into ‘/home/jeffreychi/R/x86_64-pc-linux-gnu-library/4.2’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "install.packages(c(\"RSelenium\", \"writexl\", \"here\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "509d4ace-cd23-4dd7-800e-0dfb2e2b8f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "here() starts at /home/jeffreychi/Downloads/Group Project\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CPI data\n",
    "library(magrittr)\n",
    "library(polite)\n",
    "library(rvest)\n",
    "library(here)\n",
    "library(RSelenium)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9f9ae1-d358-4a6a-8f6b-d806a37dfb00",
   "metadata": {},
   "source": [
    "Setting up Browser environment that scrapping infoshare.stats.govt.nz website\n",
    "#todo, Error in curl::curl_fetch_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb381596-5e7c-417c-b2ac-7788b13376e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in curl::curl_fetch_disk(url, x$path, handle = handle): Unrecognized content encoding type. libcurl understands deflate, gzip content encodings.\n",
     "output_type": "error",
     "traceback": [
      "Error in curl::curl_fetch_disk(url, x$path, handle = handle): Unrecognized content encoding type. libcurl understands deflate, gzip content encodings.\nTraceback:\n",
      "1. rsDriver(verbose = FALSE, browser = \"chrome\", chromever = \"106.0.5249.61\", \n .     extraCapabilities = eCaps)",
      "2. wdman::selenium(port = port, verbose = verbose, version = version, \n .     chromever = chromever, geckover = geckover, iedrver = iedrver, \n .     phantomver = phantomver, check = check)",
      "3. selenium_check(verbose, check = check)",
      "4. process_yaml(syml, verbose)",
      "5. fn({\n .     message(\"BEGIN: PREDOWNLOAD\")\n .     dllist <- do.call(ymlfuncs[[c(\"predlfunction\", \"function\")]], \n .         ymlfuncs[[c(\"predlfunction\", \"args\")]])\n .     message(\"BEGIN: DOWNLOAD\")\n .     dlfiles <- do.call(ymlfuncs[[c(\"dlfunction\", \"function\")]], \n .         c(list(dllist = dllist), ymlfuncs[[c(\"dlfunction\", \"args\")]]))\n .     message(\"BEGIN: POSTDOWNLOAD\")\n .     postproc <- do.call(ymlfuncs[[c(\"postdlfunction\", \"function\")]], \n .         c(list(dlfiles = dlfiles), ymlfuncs[[c(\"postdlfunction\", \n .             \"args\")]]))\n . })",
      "6. withCallingHandlers(expr, message = function(c) if (inherits(c, \n .     classes)) tryInvokeRestart(\"muffleMessage\"))",
      "7. do.call(ymlfuncs[[c(\"dlfunction\", \"function\")]], c(list(dllist = dllist), \n .     ymlfuncs[[c(\"dlfunction\", \"args\")]]))",
      "8. (function (dllist, overwrite = FALSE) \n . {\n .     assert_that(is_list_of_df(dllist))\n .     assert_that(is_logical(overwrite))\n .     dl_files <- function(dir, file, url) {\n .         if (!dir.exists(dir)) {\n .             pretty_message(paste0(\"Creating directory: \", dir))\n .             chk <- dir.create(dir, recursive = TRUE)\n .             stopifnot(chk)\n .         }\n .         pretty_message(paste0(\"Downloading binary: \", url), \"\\n\")\n .         wd <- httr::write_disk(file.path(dir, file), overwrite = TRUE)\n .         res <- httr::GET(url, wd)\n .         httr::stop_for_status(res)\n .         res\n .     }\n .     dlfiles <- lapply(names(dllist), function(platform) {\n .         platformDF <- dllist[[platform]]\n .         if (!overwrite) {\n .             platformDF <- platformDF[!platformDF[[\"exists\"]], \n .                 ]\n .         }\n .         if (identical(nrow(platformDF), 0L)) {\n .             return(data.frame(platform = character(), file = character(), \n .                 processed = logical(), stringsAsFactors = FALSE))\n .         }\n .         res <- Map(dl_files, dir = platformDF[[\"dir\"]], file = platformDF[[\"file\"]], \n .             url = platformDF[[\"url\"]], USE.NAMES = FALSE)\n .         res <- vapply(res, class, character(1)) == \"response\"\n .         data.frame(platform = platform, file = file.path(platformDF[[\"dir\"]], \n .             platformDF[[\"file\"]]), processed = res, stringsAsFactors = FALSE)\n .     })\n .     invisible(do.call(rbind.data.frame, dlfiles))\n . })(dllist = list(generic = structure(list(version = c(\"3.141.59\", \n . \"4.0.0-alpha-1\", \"4.0.0-alpha-2\"), url = c(\"https://www.googleapis.com/download/storage/v1/b/selenium-release/o/3.141%2Fselenium-server-standalone-3.141.59.jar?generation=1542184006302312&alt=media\", \n . \"https://www.googleapis.com/download/storage/v1/b/selenium-release/o/4.0%2Fselenium-server-standalone-4.0.0-alpha-1.jar?generation=1556122620115927&alt=media\", \n . \"https://www.googleapis.com/download/storage/v1/b/selenium-release/o/4.0%2Fselenium-server-standalone-4.0.0-alpha-2.jar?generation=1562016739229945&alt=media\"\n . ), file = c(\"selenium-server-standalone-3.141.59.jar\", \"selenium-server-standalone-4.0.0-alpha-1.jar\", \n . \"selenium-server-standalone-4.0.0-alpha-2.jar\"), dir = structure(list(\n .     \"~/.local/share/binman_seleniumserver/generic/3.141.59\", \n .     \"~/.local/share/binman_seleniumserver/generic/4.0.0-alpha-1\", \n .     \"~/.local/share/binman_seleniumserver/generic/4.0.0-alpha-2\"), names = c(\"generic\", \n . NA, NA)), exists = c(FALSE, FALSE, FALSE)), row.names = c(268L, \n . 436L, 438L), class = \"data.frame\")))",
      "9. lapply(names(dllist), function(platform) {\n .     platformDF <- dllist[[platform]]\n .     if (!overwrite) {\n .         platformDF <- platformDF[!platformDF[[\"exists\"]], ]\n .     }\n .     if (identical(nrow(platformDF), 0L)) {\n .         return(data.frame(platform = character(), file = character(), \n .             processed = logical(), stringsAsFactors = FALSE))\n .     }\n .     res <- Map(dl_files, dir = platformDF[[\"dir\"]], file = platformDF[[\"file\"]], \n .         url = platformDF[[\"url\"]], USE.NAMES = FALSE)\n .     res <- vapply(res, class, character(1)) == \"response\"\n .     data.frame(platform = platform, file = file.path(platformDF[[\"dir\"]], \n .         platformDF[[\"file\"]]), processed = res, stringsAsFactors = FALSE)\n . })",
      "10. FUN(X[[i]], ...)",
      "11. Map(dl_files, dir = platformDF[[\"dir\"]], file = platformDF[[\"file\"]], \n  .     url = platformDF[[\"url\"]], USE.NAMES = FALSE)",
      "12. mapply(FUN = f, ..., SIMPLIFY = FALSE)",
      "13. (function (dir, file, url) \n  . {\n  .     if (!dir.exists(dir)) {\n  .         pretty_message(paste0(\"Creating directory: \", dir))\n  .         chk <- dir.create(dir, recursive = TRUE)\n  .         stopifnot(chk)\n  .     }\n  .     pretty_message(paste0(\"Downloading binary: \", url), \"\\n\")\n  .     wd <- httr::write_disk(file.path(dir, file), overwrite = TRUE)\n  .     res <- httr::GET(url, wd)\n  .     httr::stop_for_status(res)\n  .     res\n  . })(dir = dots[[1L]][[1L]], file = dots[[2L]][[1L]], url = dots[[3L]][[1L]])",
      "14. httr::GET(url, wd)",
      "15. request_perform(req, hu$handle$handle)",
      "16. request_fetch(req$output, req$url, handle)",
      "17. request_fetch.write_disk(req$output, req$url, handle)",
      "18. curl::curl_fetch_disk(url, x$path, handle = handle)"
     ]
    }
   ],
   "source": [
    "data_dir = paste(here(), \"data\", sep = \"/\")\n",
    "\n",
    "eCaps <- list(\n",
    "  chromeOptions = \n",
    "    list(prefs = list(\n",
    "        \"profile.default_content_settings.popups\" = 0L,\n",
    "        \"download.prompt_for_download\" = FALSE,\n",
    "        \"directory_upgrade\" = TRUE,\n",
    "        \"download.default_directory\" = data_dir),\n",
    "      args = list(\n",
    "        \"--disable-blink-features=AutomationControlled\"\n",
    "      )),\n",
    "      useAutomationExtension = FALSE,\n",
    "      excludeSwitches = list(\n",
    "        \"enable-automation\"\n",
    "      )\n",
    ")\n",
    "\n",
    "rD <- rsDriver(verbose = FALSE, browser = \"chrome\", chromever = \"106.0.5249.61\",\n",
    "                extraCapabilities = eCaps)\n",
    "remDr <- rD$client\n",
    "remDr$maxWindowSize()\n",
    "remDr$navigate(\"https://infoshare.stats.govt.nz/infoshare/Default.aspx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ca0119-d5eb-44fb-b8fc-e43fadbd1b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Define utility function for retrieving html contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "383157eb-089d-48ee-a79f-31da2100f223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper of remoteDriver$findElement, enable wait and check for 3 times\n",
    "# rmd:  remote driver client\n",
    "# p_using: `using` param of findElement\n",
    "# p_value: `value` param of findElement\n",
    "get_tree_element <- function(rmd, p_using, p_value) {\n",
    "    sleep_secs = 2\n",
    "    vis_check = 0\n",
    "\n",
    "    # wait for progress valid\n",
    "    Sys.sleep(sleep_secs)\n",
    "    while (sleep_secs < 10 & vis_check < 30) {\n",
    "        vis = remDr$executeScript(\"return document.getElementById(arguments[0]).style.visibility\",\n",
    "                            args = list(\"ctl00_MainContent_goProgress\", \"\"))\n",
    "        # wait for progress finish\n",
    "        if (vis == \"visible\") {\n",
    "            # in progress, keep wait\n",
    "            vis_check = vis_check + 1\n",
    "            sleep_secs = 2\n",
    "            Sys.sleep(sleep_secs)\n",
    "            next\n",
    "        } else {\n",
    "            # wait for element load\n",
    "           Sys.sleep(sleep_secs) \n",
    "        }\n",
    "        \n",
    "        try(suppressMessages(rmd$findElement(using = p_using, value = p_value)), silent = TRUE)\n",
    "        if (rmd$status == 0) {\n",
    "            elem = rmd$findElement(using = p_using, value = p_value)\n",
    "            return(elem)\n",
    "        } else if (remDr$status == 7) {\n",
    "            # wait for 2 seconds\n",
    "            Sys.sleep(sleep_secs)\n",
    "        }\n",
    "        sleep_secs = sleep_secs * 2\n",
    "    }\n",
    "    return(NULL)\n",
    "}\n",
    "\n",
    "get_element <- function(rmd, p_using, p_value) {\n",
    "    sleep_secs = 2\n",
    "\n",
    "    # wait for progress valid\n",
    "    Sys.sleep(sleep_secs)\n",
    "    while (sleep_secs < 10) {\n",
    "        try(suppressMessages(rmd$findElement(using = p_using, value = p_value)), silent = TRUE)\n",
    "        if (rmd$status == 0) {\n",
    "            elem = rmd$findElement(using = p_using, value = p_value)\n",
    "            return(elem)\n",
    "        } else if (remDr$status == 7) {\n",
    "            # wait for 2 seconds\n",
    "            Sys.sleep(sleep_secs)\n",
    "        }\n",
    "        sleep_secs = sleep_secs * 2\n",
    "    }\n",
    "    return(NULL)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d025cdc-9b21-48a3-9b4d-23d0f0fe5255",
   "metadata": {},
   "source": [
    "Navigate into predefined hyperlink and retrieve contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3d0dc49-519b-49db-bdd8-b91c423eb8a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in get_tree_element(remDr, \"link text\", \"Work income and spending\"): object 'remDr' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in get_tree_element(remDr, \"link text\", \"Work income and spending\"): object 'remDr' not found\nTraceback:\n",
      "1. get_tree_element(remDr, \"link text\", \"Work income and spending\")"
     ]
    }
   ],
   "source": [
    "elem_lv_one = get_tree_element(remDr, \"link text\", \"Work income and spending\")\n",
    "elem_lv_one$clickElement()\n",
    "\n",
    "# wait for loading\n",
    "elem_lv_two = get_tree_element(remDr, \"link text\",  \"Household Labour Force Survey - HLF\")\n",
    "elem_lv_two$clickElement()\n",
    "\n",
    "elem_lv_three = get_tree_element(remDr, \"link text\", \"Labour Force Status for people aged 15 to 64 years: Seasonally Adjusted (Qrtly-Mar/Jun/Sep/Dec)\")\n",
    "elem_lv_three$clickElement()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d2cbb9-fc05-421d-8b1d-458176315266",
   "metadata": {},
   "source": [
    "Define constant variables for css selectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ae678b5-663c-4081-8438-ad938eeed3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in get_element(remDr, \"css selector\", \"span#ctl00_MainContent_ctl02_lblSelectAll\"):\n",
      "“restarting interrupted promise evaluation”\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in get_element(remDr, \"css selector\", \"span#ctl00_MainContent_ctl02_lblSelectAll\"): object 'remDr' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in get_element(remDr, \"css selector\", \"span#ctl00_MainContent_ctl02_lblSelectAll\"): object 'remDr' not found\nTraceback:\n",
      "1. get_element(remDr, \"css selector\", \"span#ctl00_MainContent_ctl02_lblSelectAll\")"
     ]
    }
   ],
   "source": [
    "# setup options of labour data for extract data\n",
    "season_adj  = get_element(remDr, \"css selector\", \"span#ctl00_MainContent_ctl02_lblSelectAll\")\n",
    "time_range  = get_element(remDr, \"css selector\", \"span#ctl00_MainContent_ctl07_lblSelectAll\")\n",
    "obs_range  = get_element(remDr, \"css selector\", \"span#ctl00_MainContent_ctl04_lblSelectAll\")\n",
    "submit  = get_element(remDr, \"css selector\", \"input#ctl00_MainContent_btnGo\")\n",
    "\n",
    "season_adj$clickElement()\n",
    "time_range$clickElement()\n",
    "obs_range$clickElement()\n",
    "submit$clickElement()\n",
    "# get footnotes for finishing page loading\n",
    "foot = get_element(remDr, \"link text\", \"Footnotes\")\n",
    "\n",
    "page_source = remDr$getPageSource()[[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478245fa-64eb-4c3e-95ff-ec627d862a7c",
   "metadata": {},
   "source": [
    "Invoke read_html method for scrapping html contents that fetches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddc1c9d9-be43-49bb-a7fa-0d8c262f2e36",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in xml2::read_html(page_source): object 'page_source' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in xml2::read_html(page_source): object 'page_source' not found\nTraceback:\n",
      "1. xml2::read_html(page_source)"
     ]
    }
   ],
   "source": [
    "# parse the page source\n",
    "doc = xml2::read_html(page_source)\n",
    "labour_table = doc %>% html_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d93ed2-3c2e-4066-8db3-d639e9e8d028",
   "metadata": {},
   "source": [
    "After sucessfully retrieve the contents from the website, we are proceed the wrangling stage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da4d9bc-3577-4fbb-849b-f3cc241c9bb1",
   "metadata": {},
   "source": [
    "Data Wrangling & Save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b39d84-f45e-4938-b194-cdbeb331724f",
   "metadata": {},
   "source": [
    "We are using R library \"visdat\" for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f8d8f7-fffb-44b5-87d9-e922edef3152",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(visdat)\n",
    "library(\"writexl\")\n",
    "\n",
    "# labour data\n",
    "labour <- labour_table[[8]]\n",
    "labour[2,1] = \"date\"\n",
    "column_name = labour[2,]\n",
    "colnames(labour) = column_name\n",
    "labour <- labour[-c(1,2),]\n",
    "labour %>% head(10)\n",
    "\n",
    "vis_dat(labour)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
